{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8043e5e9",
   "metadata": {},
   "source": [
    "# Tech Challenge PosTech - FIAP\n",
    "\n",
    "Notebook para entrega do Tech Challenge da p√≥s gradua√ß√£o em DATA Analytics na FIAP\n",
    "\n",
    "- Daniel Lins Toqueiro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17bf7c53",
   "metadata": {},
   "source": [
    "## O problema\n",
    "Voc√™ foi recentemente alocado em uma equipe de cientistas de dados de um grande fundo de investimentos brasileiro. Sua miss√£o inicial √© desenvolver um modelo preditivo capaz de **prever se o √≠ndice IBOVESPA vai fechar em alta ou baixa no dia seguinte,** com base em dados hist√≥ricos do pr√≥prio √≠ndice. Esse modelo ser√° usado como insumo para alimentar dashboards internos de tomada de decis√£o dos analistas quantitativos da empresa."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a93437",
   "metadata": {},
   "source": [
    "### Configura√ß√µes iniciais"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08465a4",
   "metadata": {},
   "source": [
    "#### Importa√ß√£o das Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "28687503",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import yfinance as yf\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a5b7b9",
   "metadata": {},
   "source": [
    "#### Configura√ß√µes de Reprodutibilidade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "fa74ccb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Semente de aleatoriedade definida para: 42\n"
     ]
    }
   ],
   "source": [
    "# FUN√á√ÉO PARA GARANTIR REPRODUTIBILIDADE\n",
    "\n",
    "def definir_semente_reprodutibilidade_aprimorada(semente):\n",
    "    \"\"\"\n",
    "    Define a semente para todas as fontes de aleatoriedade\n",
    "    para garantir a reprodutibilidade dos resultados.\n",
    "    \"\"\"\n",
    "    random.seed(semente)\n",
    "    os.environ['PYTHONHASHSEED'] = str(semente)\n",
    "    np.random.seed(semente)\n",
    "    torch.manual_seed(semente)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(semente)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "    print(f\"Semente de aleatoriedade definida para: {semente}\")\n",
    "\n",
    "# EXECU√á√ÉO DA FUN√á√ÉO\n",
    "SEMENTE_GLOBAL = 42\n",
    "\n",
    "definir_semente_reprodutibilidade_aprimorada(SEMENTE_GLOBAL)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc87dcf3",
   "metadata": {},
   "source": [
    "### Aquisi√ß√£o dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d72901d",
   "metadata": {},
   "source": [
    "Obs.: Durante as sess√µes de Grupo de Estudo o professor informou que seria poss√≠vel fazer a aquisi√ß√£o dos dados utilizando o **Yahoo Finance**, foi escolhida esta solu√ß√£o ao inv√©s de baixar manualmente os dados no site **Investing.com** porque esta alternativa permite adquirir os dados de forma program√°tica.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e35b6e",
   "metadata": {},
   "source": [
    "#### Requisitos:\n",
    "- Dados no per√≠odo ‚Äúdi√°rio‚Äù ‚úÖ\n",
    "- Intervalo de pelo menos 2 anos de dados. ‚úÖ\n",
    "- Pr√©-processamento dos dados.‚úÖ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c13110",
   "metadata": {},
   "source": [
    "#### Adquirindo os dados do Ibovespa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "31976a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Daniel\\AppData\\Local\\Temp\\ipykernel_10756\\2952932733.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  dados_ibov = yf.download(ticker, start=data_inicial, end=data_final)\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì• Baixando dados do IBOVESPA (^BVSP) de 2000-01-01 at√© 2025-07-01...\n",
      "\n",
      "‚úÖ Download conclu√≠do!\n",
      "\n",
      "üìã Primeiros 5 registros dos dados baixados:\n",
      "Price         Close     High      Low     Open Volume\n",
      "Ticker        ^BVSP    ^BVSP    ^BVSP    ^BVSP  ^BVSP\n",
      "Date                                                 \n",
      "2000-01-03  16930.0  17408.0  16719.0  17098.0      0\n",
      "2000-01-04  15851.0  16908.0  15851.0  16908.0      0\n",
      "2000-01-05  16245.0  16302.0  15350.0  15871.0      0\n",
      "2000-01-06  16107.0  16499.0  15977.0  16237.0      0\n",
      "2000-01-07  16309.0  16449.0  16125.0  16125.0      0\n",
      "\n",
      "üìã Temos 6313 dias de dados.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# O ticker para o IBOVESPA no Yahoo Finance √© '^BVSP'\n",
    "ticker = '^BVSP'\n",
    "\n",
    "# Define o per√≠odo. Vamos buscar desde 1¬∫ de janeiro de 2010 para garantir um intervalo grande, como sugerido. \n",
    "data_inicial = '2000-01-01'\n",
    "data_final = '2025-07-01' \n",
    "\n",
    "#Baixando os dados hist√≥ricos do IBOVESPA\n",
    "print(f\"üì• Baixando dados do IBOVESPA ({ticker}) de {data_inicial} at√© {data_final}...\\n\")\n",
    "dados_ibov = yf.download(ticker, start=data_inicial, end=data_final)\n",
    "print(\"‚úÖ Download conclu√≠do!\")\n",
    "\n",
    "# Visualiza√ß√£o dos primeiros registros do Ibovespa\n",
    "print(\"\\nüìã Primeiros 5 registros dos dados baixados:\")\n",
    "print(dados_ibov.head())\n",
    "\n",
    "print(f\"\\nüìã Temos {len(dados_ibov)} dias de dados.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2bb0705",
   "metadata": {},
   "source": [
    "#### Realizando o pr√©-processamento - Ibovespa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "3d284e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descartando dados desnecess√°rios e renomeando colunas\n",
    "# Mantendo apenas as colunas relevantes: 'Close', 'High', 'Low', 'Open', 'Volume'\n",
    "# E renomeando a coluna de data para 'Date' e definindo como √≠ndice\n",
    "dados_ibov = dados_ibov[['Close', \"High\", \"Low\", \"Open\", \"Volume\"]].dropna().reset_index()\n",
    "dados_ibov.columns = ['Date', 'Close', 'High', 'Low', 'Open', 'Volume']\n",
    "dados_ibov.set_index('Date', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094d287a",
   "metadata": {},
   "source": [
    "#### Dolar\n",
    "Al√©m dos dados do Ibovespa puxamos tamb√©m a s√©rie hist√≥rica do **Dolar** para utilizar em nosso modelo, tamb√©m vamos puxar os dados utilizando o Yahoo Finance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "c24c224d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì• Baixando dados do Dolar (USDBRL=X) de 2000-01-01 at√© 2025-07-01...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Daniel\\AppData\\Local\\Temp\\ipykernel_10756\\3089713958.py:6: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  dados_dolar = yf.download(ticker, start=data_inicial, end=data_final)\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Download conclu√≠do!\n",
      "\n",
      "üìã Primeiros 5 registros dos dados baixados:\n",
      "Price         Close     High      Low     Open   Volume\n",
      "Ticker     USDBRL=X USDBRL=X USDBRL=X USDBRL=X USDBRL=X\n",
      "Date                                                   \n",
      "2003-12-01    2.923    2.946    2.923    2.946        0\n",
      "2003-12-02    2.931    2.931    2.923    2.923        0\n",
      "2003-12-03    2.931    2.936    2.926    2.931        0\n",
      "2003-12-04    2.943    2.943    2.931    2.931        0\n",
      "2003-12-05    2.934    2.948    2.934    2.943        0\n",
      "\n",
      "üìã Temos 5181 dias de dados.\n"
     ]
    }
   ],
   "source": [
    "# O ticker para o Dolar no Yahoo Finance √© 'USDBRL=X'\n",
    "ticker = \"USDBRL=X\"\n",
    "\n",
    "#Usaremos as mesmas datas para o D√≥lar, de 1¬∫ de janeiro de 2010 at√© 1¬∫ de julho de 2025\n",
    "print(f\"üì• Baixando dados do Dolar ({ticker}) de {data_inicial} at√© {data_final}...\\n\")\n",
    "dados_dolar = yf.download(ticker, start=data_inicial, end=data_final)\n",
    "print(\"‚úÖ Download conclu√≠do!\")\n",
    "# Visualiza√ß√£o dos primeiros registros do D√≥lar\n",
    "print(\"\\nüìã Primeiros 5 registros dos dados baixados:\")\n",
    "print(dados_dolar.head())\n",
    "\n",
    "print(f\"\\nüìã Temos {len(dados_dolar)} dias de dados.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d931879",
   "metadata": {},
   "source": [
    "#### Realizando o pr√©-processamento - Dolar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "b33930b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descartando dados desnecess√°rios e renomeando colunas\n",
    "# Mantendo apenas as colunas relevantes: 'Close', 'High', 'Low', 'Open', 'Volume'\n",
    "# E renomeando a coluna de data para 'Date' e definindo como √≠ndice\n",
    "dados_dolar = dados_dolar[['Close', \"High\", \"Low\", \"Open\", \"Volume\"]].dropna().reset_index()\n",
    "dados_dolar.columns = ['Date', 'Close', 'High', 'Low', 'Open', 'Volume']\n",
    "dados_dolar.set_index('Date', inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a8e743",
   "metadata": {},
   "source": [
    "#### Juntando os dados - Ibovespa e Dolar\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "3d81d6b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dados combinados do IBOVESPA e D√≥lar:\n",
      "              Close     High      Low     Open  Volume  Close_Dolar  \\\n",
      "Date                                                                  \n",
      "2003-12-01  20521.0  20522.0  20184.0  20184.0       0        2.923   \n",
      "2003-12-02  20458.0  20630.0  20354.0  20523.0       0        2.931   \n",
      "2003-12-03  20540.0  20586.0  20322.0  20462.0       0        2.931   \n",
      "2003-12-04  20414.0  20570.0  20323.0  20540.0       0        2.943   \n",
      "2003-12-05  20880.0  20922.0  20418.0  20418.0       0        2.934   \n",
      "\n",
      "            High_Dolar  Low_Dolar  Open_Dolar  Volume_Dolar  \n",
      "Date                                                         \n",
      "2003-12-01       2.946      2.923       2.946             0  \n",
      "2003-12-02       2.931      2.923       2.923             0  \n",
      "2003-12-03       2.936      2.926       2.931             0  \n",
      "2003-12-04       2.943      2.931       2.931             0  \n",
      "2003-12-05       2.948      2.934       2.943             0  \n"
     ]
    }
   ],
   "source": [
    "#Juntando os dados do IBOVESPA e do D√≥lar\n",
    "dados_ibov = dados_ibov.merge(dados_dolar, on='Date', suffixes=('','_Dolar'))\n",
    "# Removendo dados nulls que podem ter surgido na jun√ß√£o\n",
    "dados_ibov = dados_ibov.dropna()\n",
    "print(\"\\nDados combinados do IBOVESPA e D√≥lar:\")\n",
    "print(dados_ibov.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f287810a",
   "metadata": {},
   "source": [
    "### Engenharia de Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "8fc6fe02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìã Criando DataFrame com as colunas relevantes...\n",
      "Dados carregados com sucesso!\n",
      "\n",
      "üìã Criando a vari√°vel alvo (Target)...\n",
      "\n",
      "üìã Calculando a varia√ß√£o percentual di√°ria...\n",
      "\n",
      "üìã Criando atributos de lags...\n",
      "\n",
      "üìã Criando m√©dias m√≥veis e m√©dias exponenciais...\n",
      "\n",
      "üìã Limpando dados nulos...\n",
      "\n",
      "üìã Removendo colunas auxiliares...\n",
      "\n",
      "DataFrame ap√≥s a Engenharia de Atributos com varia√ß√£o percentual:\n",
      "            Target  Daily_Change_Dolar  Daily_Change_lag_1  \\\n",
      "Date                                                         \n",
      "2004-01-19       1            0.003891            0.008405   \n",
      "2004-01-20       0            0.000000            0.009933   \n",
      "2004-01-21       0            0.001762            0.012572   \n",
      "2004-01-22       1           -0.005276           -0.015921   \n",
      "2004-01-23       1            0.004243           -0.014291   \n",
      "\n",
      "            Daily_Change_lag_2  Daily_Change_lag_5  Daily_Change_lag_10  \\\n",
      "Date                                                                      \n",
      "2004-01-19           -0.018676            0.013380             0.048429   \n",
      "2004-01-20            0.008405           -0.012254             0.001870   \n",
      "2004-01-21            0.009933           -0.022598            -0.010859   \n",
      "2004-01-22            0.012572           -0.018676             0.017024   \n",
      "2004-01-23           -0.015921            0.008405             0.008433   \n",
      "\n",
      "            Daily_Change_lag_15  Daily_Change_lag_20  Daily_Change_lag_25  \\\n",
      "Date                                                                        \n",
      "2004-01-19             0.002681             0.002414             0.017761   \n",
      "2004-01-20             0.005487             0.021146            -0.013500   \n",
      "2004-01-21             0.010914             0.013680             0.015401   \n",
      "2004-01-22             0.008664            -0.004793            -0.015120   \n",
      "2004-01-23             0.009399             0.011409            -0.012587   \n",
      "\n",
      "            Daily_Change_lag_30  ...  MA_10_Daily_Change  EMA_10_Daily_Change  \\\n",
      "Date                             ...                                            \n",
      "2004-01-19            -0.003070  ...           -0.000534             0.001236   \n",
      "2004-01-20             0.004008  ...            0.000536             0.003297   \n",
      "2004-01-21            -0.006134  ...            0.000030            -0.000197   \n",
      "2004-01-22             0.022827  ...           -0.003102            -0.002760   \n",
      "2004-01-23             0.000431  ...           -0.001759             0.001716   \n",
      "\n",
      "            MA_15_Daily_Change  EMA_15_Daily_Change  MA_20_Daily_Change  \\\n",
      "Date                                                                      \n",
      "2004-01-19            0.005170             0.002237            0.006084   \n",
      "2004-01-20            0.005642             0.003529            0.005655   \n",
      "2004-01-21            0.003853             0.001098            0.004175   \n",
      "2004-01-22            0.002323            -0.000826            0.003700   \n",
      "2004-01-23            0.003154             0.002009            0.004222   \n",
      "\n",
      "            EMA_20_Daily_Change  MA_25_Daily_Change  EMA_25_Daily_Change  \\\n",
      "Date                                                                       \n",
      "2004-01-19             0.002702            0.003931             0.002818   \n",
      "2004-01-20             0.003642            0.004974             0.003568   \n",
      "2004-01-21             0.001778            0.003721             0.002069   \n",
      "2004-01-22             0.000248            0.003755             0.000811   \n",
      "2004-01-23             0.002306            0.005132             0.002430   \n",
      "\n",
      "            MA_30_Daily_Change  EMA_30_Daily_Change  \n",
      "Date                                                 \n",
      "2004-01-19            0.004573             0.002750  \n",
      "2004-01-20            0.004858             0.003384  \n",
      "2004-01-21            0.004532             0.002138  \n",
      "2004-01-22            0.003295             0.001078  \n",
      "2004-01-23            0.004009             0.002419  \n",
      "\n",
      "[5 rows x 22 columns]\n",
      "\n",
      "√öltimos 5 registros:\n",
      "            Target  Daily_Change_Dolar  Daily_Change_lag_1  \\\n",
      "Date                                                         \n",
      "2025-06-24       0           -0.004458           -0.004121   \n",
      "2025-06-25       1            0.003003            0.004496   \n",
      "2025-06-26       0            0.008638           -0.010192   \n",
      "2025-06-27       1           -0.014538            0.009921   \n",
      "2025-06-30       0            0.000237           -0.001809   \n",
      "\n",
      "            Daily_Change_lag_2  Daily_Change_lag_5  Daily_Change_lag_10  \\\n",
      "Date                                                                      \n",
      "2025-06-24           -0.011541            0.014889            -0.002961   \n",
      "2025-06-25           -0.004121           -0.002987             0.005431   \n",
      "2025-06-26            0.004496           -0.000886             0.005072   \n",
      "2025-06-27           -0.010192           -0.011541             0.004901   \n",
      "2025-06-30            0.009921           -0.004121            -0.004260   \n",
      "\n",
      "            Daily_Change_lag_15  Daily_Change_lag_20  Daily_Change_lag_25  \\\n",
      "Date                                                                        \n",
      "2025-06-24            -0.001751             0.002264             0.003226   \n",
      "2025-06-25             0.005549             0.010171             0.003395   \n",
      "2025-06-26            -0.003955            -0.004680            -0.015909   \n",
      "2025-06-27            -0.005591            -0.002549            -0.004410   \n",
      "2025-06-30            -0.000984            -0.010878             0.004014   \n",
      "\n",
      "            Daily_Change_lag_30  ...  MA_10_Daily_Change  EMA_10_Daily_Change  \\\n",
      "Date                             ...                                            \n",
      "2025-06-24             0.000374  ...            0.001099            -0.000467   \n",
      "2025-06-25             0.017574  ...           -0.000463            -0.002235   \n",
      "2025-06-26            -0.003886  ...            0.000022            -0.000025   \n",
      "2025-06-27             0.006581  ...           -0.000649            -0.000349   \n",
      "2025-06-30            -0.001055  ...            0.001230             0.002357   \n",
      "\n",
      "            MA_15_Daily_Change  EMA_15_Daily_Change  MA_20_Daily_Change  \\\n",
      "Date                                                                      \n",
      "2025-06-24            0.000203            -0.000267           -0.000332   \n",
      "2025-06-25           -0.000846            -0.001507           -0.001350   \n",
      "2025-06-26            0.000079            -0.000079           -0.000620   \n",
      "2025-06-27            0.000331            -0.000295           -0.000583   \n",
      "2025-06-30            0.001366             0.001558            0.000688   \n",
      "\n",
      "            EMA_20_Daily_Change  MA_25_Daily_Change  EMA_25_Daily_Change  \\\n",
      "Date                                                                       \n",
      "2025-06-24            -0.000105           -0.000691             0.000044   \n",
      "2025-06-25            -0.001065           -0.001235            -0.000743   \n",
      "2025-06-26            -0.000019           -0.000201             0.000077   \n",
      "2025-06-27            -0.000189           -0.000097            -0.000068   \n",
      "2025-06-30             0.001213            0.000323             0.001055   \n",
      "\n",
      "            MA_30_Daily_Change  EMA_30_Daily_Change  \n",
      "Date                                                 \n",
      "2025-06-24            0.000172             0.000176  \n",
      "2025-06-25           -0.000754            -0.000493  \n",
      "2025-06-26           -0.000293             0.000179  \n",
      "2025-06-27           -0.000573             0.000051  \n",
      "2025-06-30           -0.000053             0.000985  \n",
      "\n",
      "[5 rows x 22 columns]\n",
      "\n",
      "‚úÖO DataFrame final agora tem 4888 linhas e 22 colunas.\n",
      "‚úÖAs colunas s√£o: ['Target', 'Daily_Change_Dolar', 'Daily_Change_lag_1', 'Daily_Change_lag_2', 'Daily_Change_lag_5', 'Daily_Change_lag_10', 'Daily_Change_lag_15', 'Daily_Change_lag_20', 'Daily_Change_lag_25', 'Daily_Change_lag_30', 'MA_5_Daily_Change', 'EMA_5_Daily_Change', 'MA_10_Daily_Change', 'EMA_10_Daily_Change', 'MA_15_Daily_Change', 'EMA_15_Daily_Change', 'MA_20_Daily_Change', 'EMA_20_Daily_Change', 'MA_25_Daily_Change', 'EMA_25_Daily_Change', 'MA_30_Daily_Change', 'EMA_30_Daily_Change']\n"
     ]
    }
   ],
   "source": [
    "# Criamos um DataFrame para trabalhar com as features\n",
    "# Vamos manter apenas as colunas de fechamento e fechamento do d√≥lar\n",
    "# para facilitar a engenharia de atributos\n",
    "print(\"\\nüìã Criando DataFrame com as colunas relevantes...\")\n",
    "df = dados_ibov[['Close','Close_Dolar']].copy()\n",
    "print(\"Dados carregados com sucesso!\")\n",
    "\n",
    "# Criamos a vari√°vel alvo (Target)\n",
    "# O alvo continua sendo a tend√™ncia de alta (1) ou baixa (0) do fechamento do dia seguinte\n",
    "print(\"\\nüìã Criando a vari√°vel alvo (Target)...\")\n",
    "df['Target'] = (df['Close'].shift(-1) > df['Close']).astype(int)\n",
    "\n",
    "# Criamos a coluna de varia√ß√£o percentual\n",
    "# Vamos calcular a varia√ß√£o di√°ria para ser a nossa feature principal\n",
    "print(\"\\nüìã Calculando a varia√ß√£o percentual di√°ria...\")\n",
    "df['Daily_Change'] = df['Close'].pct_change()\n",
    "df['Daily_Change_Dolar'] = df['Close_Dolar'].pct_change()\n",
    "\n",
    "# Criamos os atributos de \"lag\" (valores passados) baseados na varia√ß√£o percentual\n",
    "# O modelo vai prever a tend√™ncia do dia seguinte com base nas varia√ß√µes dos dias anteriores\n",
    "print(\"\\nüìã Criando atributos de lags...\")\n",
    "janela_lags = [1, 2, 5, 10, 15, 20, 25, 30] # Exemplo de janelas de tempo para os lags\n",
    "for i in janela_lags:\n",
    "    df[f'Daily_Change_lag_{i}'] = df['Daily_Change'].shift(i)\n",
    "\n",
    "# Criamos atributos de M√©dias M√≥veis e M√©dias Exponenciais baseados na varia√ß√£o percentual\n",
    "# Isso ajuda a suavizar a volatilidade e identificar tend√™ncias de varia√ß√£o\n",
    "print(\"\\nüìã Criando m√©dias m√≥veis e m√©dias exponenciais...\")\n",
    "janela_medias_moveis = [5, 10, 15, 20, 25, 30] # Janelas de tempo para as m√©dias m√≥veis\n",
    "for i in janela_medias_moveis:\n",
    "    df[f'MA_{i}_Daily_Change'] = df['Daily_Change'].rolling(window=i).mean()\n",
    "    df[f'EMA_{i}_Daily_Change'] = df['Daily_Change'].ewm(span=i, adjust=False).mean()\n",
    "\n",
    "\n",
    "# Limpamos os dados nulos\n",
    "# A cria√ß√£o de lags e m√©dias m√≥veis resulta em valores nulos (NaN) no in√≠cio do DataFrame.\n",
    "# Tamb√©m o √∫ltimo dia ter√° NaN na coluna 'Target'.\n",
    "# Al√©m disso, a coluna 'Close_Dolar' pode ter NaN se o D√≥lar n√£o tiver cota√ß√£o naquele dia.\n",
    "print(\"\\nüìã Limpando dados nulos...\")\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Removendo as colunas auxiliares que n√£o ser√£o features\n",
    "# As colunas 'Close' 'Close_Dolar' e 'Daily_Change' foram usadas para criar as features, \n",
    "# mas o valor absoluto delas pode n√£o ser √∫til se usarmos os lags e as m√©dias.\n",
    "# √© uma boa pr√°tica usar apenas as features derivadas para evitar vazamento de dados (data leakage) e multicolinearidade.\n",
    "print(\"\\nüìã Removendo colunas auxiliares...\")\n",
    "df.drop(['Close', 'Daily_Change', 'Close_Dolar'], axis=1, inplace=True)\n",
    "\n",
    "print(\"\\nDataFrame ap√≥s a Engenharia de Atributos com varia√ß√£o percentual:\")\n",
    "print(df.head())\n",
    "print(\"\\n√öltimos 5 registros:\")\n",
    "print(df.tail())\n",
    "\n",
    "print(f\"\\n‚úÖO DataFrame final agora tem {len(df)} linhas e {len(df.columns)} colunas.\")\n",
    "print(\"‚úÖAs colunas s√£o:\", list(df.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80a8114",
   "metadata": {},
   "source": [
    "### Modelo LTSM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f1ed2b",
   "metadata": {},
   "source": [
    "#### Introdu√ß√£o\n",
    "O LTSM (Long Short-Term Memory ou Mem√≥ria de Longo e Curto Prazo) √© um tipo especial de rede neural projetada para reconhecer padr√µes em sequ√™ncias de dados, como, por exemplo, os dados hist√≥ricos de uma bolsa de valores. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d783802f",
   "metadata": {},
   "source": [
    "#### Janelas de Tempo\n",
    "Para um modelo de s√©rie temporal como a LSTM, voc√™ precisa criar \"janelas deslizantes\" de dados. Por exemplo, use os dados dos √∫ltimos 30 dias para prever a tend√™ncia do dia 31.\n",
    "A t√©cnica de Janelas de Tempo prepara o modelo para analisar o comportamento dos √∫ltimos 30 dias (no nosso caso) para identificar uma tend√™ncia.\n",
    "√â uma forma de preparar os dados, transformando uma longa s√©rie hist√≥rica (como anos de dados do IBOVESPA) em centenas de pequenos \"mini-exemplos\" de causa e efeito que o modelo pode aprender."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "a15b4b00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìã Definindo o tamanho da janela de tempo...\n",
      "\n",
      "üìã Separando as features e o alvo...\n",
      "\n",
      "üìãCriando janelas de tempo de 30 dias...\n",
      "‚úÖ Janelas de tempo criadas com sucesso!\n",
      "Formato de X (janelas de features): (4858, 30, 21)\n",
      "Formato de y (alvos): (4858,)\n",
      "\n",
      "üìã Convertendo os dados para tensores do PyTorch...\n",
      "\n",
      "‚úÖ Dados convertidos para tensores do PyTorch!\n",
      "‚úÖ Formato do tensor X: torch.Size([4858, 30, 21])\n",
      "‚úÖ Formato do tensor y: torch.Size([4858])\n"
     ]
    }
   ],
   "source": [
    "# Agora que temos o DataFrame pronto, vamos criar as janelas de tempo\n",
    "# Definindo o tamanho da janela de tempo\n",
    "# Vamos usar uma janela de 30 dias, que √© a recomenda√ß√£o para o conjunto de testes\n",
    "print(\"\\nüìã Definindo o tamanho da janela de tempo...\")\n",
    "tamanho_janela = 30\n",
    "\n",
    "#Separamos as features e o alvo\n",
    "print(\"\\nüìã Separando as features e o alvo...\")\n",
    "# As colunas de features s√£o todas as colunas, exceto a coluna 'Target'\n",
    "# A coluna 'Target' √© a nossa vari√°vel dependente\n",
    "features = df.drop('Target', axis=1).values\n",
    "target = df['Target'].values\n",
    "\n",
    "#Criando a fun√ß√£o para construir as janelas de tempo\n",
    "def criar_janelas_de_tempo(features, target, tamanho_janela):\n",
    "    X, y = [], []\n",
    "    for i in range(len(features) - tamanho_janela):\n",
    "        # Pega a janela de tempo das features\n",
    "        janela_features = features[i:(i + tamanho_janela)]\n",
    "        X.append(janela_features)\n",
    "        \n",
    "        # O alvo √© o valor 'Target' do dia seguinte √† janela\n",
    "        y.append(target[i + tamanho_janela])\n",
    "    \n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "#Criando as janelas e os alvos\n",
    "print(f\"\\nüìãCriando janelas de tempo de {tamanho_janela} dias...\")\n",
    "X, y = criar_janelas_de_tempo(features, target, tamanho_janela)\n",
    "\n",
    "print(\"‚úÖ Janelas de tempo criadas com sucesso!\")\n",
    "print(f\"Formato de X (janelas de features): {X.shape}\") # Exemplo: (1200, 30, 8)\n",
    "print(f\"Formato de y (alvos): {y.shape}\") # Exemplo: (1200,)\n",
    "\n",
    "# Convertendo os dados para tensores do PyTorch\n",
    "print(\"\\nüìã Convertendo os dados para tensores do PyTorch...\")\n",
    "X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y, dtype=torch.long) \n",
    "\n",
    "print(\"\\n‚úÖ Dados convertidos para tensores do PyTorch!\")\n",
    "print(f\"‚úÖ Formato do tensor X: {X_tensor.shape}\")\n",
    "print(f\"‚úÖ Formato do tensor y: {y_tensor.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a862b710",
   "metadata": {},
   "source": [
    "#### Separando os dados em Treino e Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "67759865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìã Verificando o n√∫mero total de registros e o n√∫mero de features...\n",
      "‚úÖ N√∫mero total de registros (janelas): 4858\n",
      "‚úÖ N√∫mero de features por janela: 21\n",
      "\n",
      "üìã Separando os dados em conjuntos de treino e teste...\n",
      "‚úÖ Dados separados com sucesso!\n",
      "Formato do conjunto de treino: torch.Size([4828, 30, 21]), torch.Size([4828])\n",
      "Tamanho do conjunto de treino: 4828\n",
      "\n",
      "Formato do conjunto de teste: torch.Size([30, 30, 21]), torch.Size([30])\n",
      "Tamanho do conjunto de teste: 30\n"
     ]
    }
   ],
   "source": [
    "# Verificando o n√∫mero total de registros e o n√∫mero de features\n",
    "# Aqui, num_registros_totais √© o n√∫mero total de janelas de tempo criadas\n",
    "# num_features √© o n√∫mero de features em cada janela de tempo\n",
    "print(\"\\nüìã Verificando o n√∫mero total de registros e o n√∫mero de features...\")\n",
    "num_registros_totais = X.shape[0]\n",
    "num_features = X.shape[2]\n",
    "print(f\"‚úÖ N√∫mero total de registros (janelas): {num_registros_totais}\")\n",
    "print(f\"‚úÖ N√∫mero de features por janela: {num_features}\")\n",
    "\n",
    "# Separando os dados em conjuntos de treino e teste\n",
    "# Conforme o requisito do projeto, o conjunto de testes deve conter os √∫ltimos 30 dias de dados.\n",
    "# Como cada janela √© de 30 dias, e os alvos correspondem ao dia seguinte,\n",
    "# 30 dias de teste correspondem a 30 janelas de teste.\n",
    "print(\"\\nüìã Separando os dados em conjuntos de treino e teste...\")\n",
    "num_dias_teste = 30 \n",
    "num_janelas_teste = num_dias_teste\n",
    "# O tamanho do nosso conjunto de treino ser√° o restante\n",
    "num_janelas_treino = len(X_tensor) - num_janelas_teste\n",
    "\n",
    "X_treino = X_tensor[:num_janelas_treino]\n",
    "y_treino = y_tensor[:num_janelas_treino]\n",
    "\n",
    "X_teste = X_tensor[num_janelas_treino:]\n",
    "y_teste = y_tensor[num_janelas_treino:]\n",
    "\n",
    "print(\"‚úÖ Dados separados com sucesso!\")\n",
    "print(f\"Formato do conjunto de treino: {X_treino.shape}, {y_treino.shape}\")\n",
    "print(f\"Tamanho do conjunto de treino: {len(X_treino)}\")\n",
    "print(f\"\\nFormato do conjunto de teste: {X_teste.shape}, {y_teste.shape}\")\n",
    "print(f\"Tamanho do conjunto de teste: {len(X_teste)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e7e997",
   "metadata": {},
   "source": [
    "#### Normalizando os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "2dfd3b48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìã Calculando a m√©dia e o desvio padr√£o do conjunto de treino...\n",
      "\n",
      "Par√¢metros de normaliza√ß√£o calculados (m√©dia e desvio padr√£o do treino):\n",
      "M√©dia: tensor([0.0002, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005,\n",
      "        0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005,\n",
      "        0.0005, 0.0005, 0.0005])\n",
      "Desvio Padr√£o: tensor([0.0123, 0.0194, 0.0194, 0.0194, 0.0194, 0.0194, 0.0194, 0.0194, 0.0194,\n",
      "        0.0082, 0.0083, 0.0057, 0.0058, 0.0047, 0.0047, 0.0041, 0.0041, 0.0037,\n",
      "        0.0037, 0.0034, 0.0034])\n",
      "\n",
      "üìã Aplicando a normaliza√ß√£o em ambos os conjuntos...\n",
      "\n",
      "üìã Verificando a normaliza√ß√£o dos dados...\n",
      "Primeira janela do conjunto de treino original:\n",
      "tensor([ 0.0039,  0.0084, -0.0187,  0.0134,  0.0484,  0.0027,  0.0024,  0.0178,\n",
      "        -0.0031, -0.0070,  0.0008, -0.0005,  0.0012,  0.0052,  0.0022,  0.0061,\n",
      "         0.0027,  0.0039,  0.0028,  0.0046,  0.0028])\n",
      "Primeira janela do conjunto de treino normalizado:\n",
      "tensor([ 0.2987,  0.4057, -0.9914,  0.6623,  2.4684,  0.1106,  0.0968,  0.8867,\n",
      "        -0.1859, -0.9271,  0.0301, -0.1876,  0.1201,  0.9819,  0.3582,  1.3444,\n",
      "         0.5252,  0.9136,  0.6176,  1.1819,  0.6558])\n",
      "\n",
      "‚úÖ Dados normalizados com sucesso!\n",
      "\n",
      "Formato final dos dados:\n",
      "X_treino normalizado: torch.Size([4828, 30, 21])\n",
      "y_treino: torch.Size([4828])\n",
      "X_teste normalizado: torch.Size([30, 30, 21])\n",
      "y_teste: torch.Size([30])\n"
     ]
    }
   ],
   "source": [
    "# normalizando os dados\n",
    "\n",
    "\n",
    "# Calculando a m√©dia e o desvio padr√£o APENAS no conjunto de treino\n",
    "# Precisamos calcular a m√©dia e o desvio padr√£o para cada feature, em todas as janelas e em todos os dias\n",
    "# Para isso, vamos \"achatar\" as dimens√µes de janela e tempo\n",
    "# X_treino.view(-1, num_features) transforma o tensor para (total_dias_treino, num_features)\n",
    "treino_flat = X_treino.view(-1, num_features)\n",
    "media_treino = treino_flat.mean(dim=0)\n",
    "desvio_padrao_treino = treino_flat.std(dim=0)\n",
    "\n",
    "print(\"\\nüìã Calculando a m√©dia e o desvio padr√£o do conjunto de treino...\")\n",
    "print(\"\\nPar√¢metros de normaliza√ß√£o calculados (m√©dia e desvio padr√£o do treino):\")\n",
    "print(f\"M√©dia: {media_treino}\")\n",
    "print(f\"Desvio Padr√£o: {desvio_padrao_treino}\")\n",
    "\n",
    "\n",
    "# Aplicando a normaliza√ß√£o em ambos os conjuntos\n",
    "# Normaliza√ß√£o (Standard Scaling): (x - media) / desvio_padrao\n",
    "print(\"\\nüìã Aplicando a normaliza√ß√£o em ambos os conjuntos...\")\n",
    "X_treino_normalizado = (X_treino - media_treino) / desvio_padrao_treino\n",
    "X_teste_normalizado = (X_teste - media_treino) / desvio_padrao_treino # ATEN√á√ÉO: usa os par√¢metros do treino!\n",
    "\n",
    "# Verificando se a normaliza√ß√£o foi aplicada corretamente\n",
    "print(\"\\nüìã Verificando a normaliza√ß√£o dos dados...\")\n",
    "print(\"Primeira janela do conjunto de treino original:\")\n",
    "print(X_treino[0, 0, :]) # Mostra a primeira linha da primeira janela\n",
    "print(\"Primeira janela do conjunto de treino normalizado:\")\n",
    "print(X_treino_normalizado[0, 0, :]) # Mostra a primeira linha da primeira janela normalizada\n",
    "\n",
    "# O y_treino e y_teste n√£o precisam ser normalizados, pois s√£o os r√≥tulos (0 ou 1)\n",
    "y_treino_final = y_treino\n",
    "y_teste_final = y_teste\n",
    "\n",
    "print(\"\\n‚úÖ Dados normalizados com sucesso!\")\n",
    "print(\"\\nFormato final dos dados:\")\n",
    "print(f\"X_treino normalizado: {X_treino_normalizado.shape}\")\n",
    "print(f\"y_treino: {y_treino_final.shape}\")\n",
    "print(f\"X_teste normalizado: {X_teste_normalizado.shape}\")\n",
    "print(f\"y_teste: {y_teste_final.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1269344",
   "metadata": {},
   "source": [
    "#### Dataset e DataLoader\n",
    "\n",
    "Cria√ß√£o do Conjunto de Dados e Carregador (Dataset e DataLoader):\n",
    "- Classe Dataset em PyTorch para carregar seus dados pr√©-processados e as janelas de tempo.\n",
    "- DataLoader para carregar os dados em lotes (batches), o que √© mais eficiente para o treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "b8c92f4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìã Criando os objetos Dataset e DataLoader...\n",
      "\n",
      "‚úÖ Objetos 'Dataset' criados com sucesso!\n",
      "Tamanho do dataset de treino: 4828 amostras.\n",
      "Tamanho do dataset de teste: 30 amostras.\n",
      "\n",
      "üìã Criando os objetos DataLoader...\n",
      "‚úÖ Objetos 'DataLoader' criados com sucesso!\n",
      "Tamanho do lote (batch size): 64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Agora que temos os dados normalizados, vamos criar os objetos Dataset e DataLoader\n",
    "\n",
    "print(\"\\nüìã Criando os objetos Dataset e DataLoader...\")\n",
    "\n",
    "#Criar uma classe Dataset personalizada\n",
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        # Inicializa o dataset com os tensores de features e targets\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        # Retorna o n√∫mero total de amostras (janelas)\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Retorna uma amostra (janela de features) e seu r√≥tulo correspondente\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "# Instanciabdo os objetos Dataset para treino e teste\n",
    "dataset_treino = TimeSeriesDataset(X_treino_normalizado, y_treino_final)\n",
    "dataset_teste = TimeSeriesDataset(X_teste_normalizado, y_teste_final)\n",
    "print(\"\\n‚úÖ Objetos 'Dataset' criados com sucesso!\")\n",
    "print(f\"Tamanho do dataset de treino: {len(dataset_treino)} amostras.\")\n",
    "print(f\"Tamanho do dataset de teste: {len(dataset_teste)} amostras.\")\n",
    "\n",
    "# Agora vamos criar os objetos DataLoader\n",
    "# O DataLoader √© respons√°vel por carregar os dados em lotes (batches) durante o treinamento\n",
    "# Isso √© mais eficiente do que carregar todos os dados de uma vez, especialmente para grandes conjuntos de dados.\n",
    "\n",
    "print(\"\\nüìã Criando os objetos DataLoader...\")\n",
    "tamanho_lote = 64 # Este √© um hiperpar√¢metro ajust√°vel\n",
    "# Um tamanho de lote (batch size) maior pode acelerar o treinamento,\n",
    "# mas consome mais mem√≥ria. 64 √© um bom valor inicial.\n",
    "\n",
    "# DataLoader de treino:\n",
    "# - 'batch_size': n√∫mero de amostras por lote\n",
    "# - 'shuffle=True': embaralha os dados em cada √©poca, o que ajuda o modelo\n",
    "#   a n√£o aprender a ordem dos dados e melhora a generaliza√ß√£o.\n",
    "dataloader_treino = DataLoader(dataset_treino, batch_size=tamanho_lote, shuffle=True)\n",
    "\n",
    "# DataLoader de teste:\n",
    "# - 'shuffle=False': n√£o √© necess√°rio embaralhar os dados de teste.\n",
    "dataloader_teste = DataLoader(dataset_teste, batch_size=tamanho_lote, shuffle=False)\n",
    "\n",
    "print(\"‚úÖ Objetos 'DataLoader' criados com sucesso!\")\n",
    "print(f\"Tamanho do lote (batch size): {tamanho_lote}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3067ac8e",
   "metadata": {},
   "source": [
    "#### Treinamento do Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "15f5a31f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìã Definindo o modelo de rede neural...\n",
      "\n",
      "üìã Configurando os par√¢metros do modelo...\n",
      "Semente de aleatoriedade definida para: 42\n",
      "\n",
      "‚úÖ Par√¢metros do modelo configurados com sucesso!\n",
      "Dispositivo usado: cuda\n",
      "N√∫mero de √©pocas: 40\n",
      "Tamanho do lote (batch size): 64\n",
      "N√∫mero de features: 21\n",
      "Tamanho do hidden layer: 64\n",
      "N√∫mero de camadas LSTM: 3\n",
      "Tamanho da sa√≠da (output size): 2\n",
      "\n",
      "üìã Iniciando o treinamento com salvamento de checkpoint...\n",
      "√âpoca [1/40], Perda: 0.6942, Acur√°cia de Treino: 51.72%, Acur√°cia de Teste: 40.00%\n",
      "  --> Modelo salvo com a melhor acur√°cia de teste: 40.00%\n",
      "√âpoca [2/40], Perda: 0.6931, Acur√°cia de Treino: 51.72%, Acur√°cia de Teste: 40.00%\n",
      "√âpoca [3/40], Perda: 0.6925, Acur√°cia de Treino: 51.91%, Acur√°cia de Teste: 43.33%\n",
      "  --> Modelo salvo com a melhor acur√°cia de teste: 43.33%\n",
      "√âpoca [4/40], Perda: 0.6931, Acur√°cia de Treino: 51.72%, Acur√°cia de Teste: 40.00%\n",
      "√âpoca [5/40], Perda: 0.6930, Acur√°cia de Treino: 51.72%, Acur√°cia de Teste: 40.00%\n",
      "√âpoca [6/40], Perda: 0.6929, Acur√°cia de Treino: 51.72%, Acur√°cia de Teste: 40.00%\n",
      "√âpoca [7/40], Perda: 0.6929, Acur√°cia de Treino: 51.72%, Acur√°cia de Teste: 40.00%\n",
      "√âpoca [8/40], Perda: 0.6929, Acur√°cia de Treino: 51.72%, Acur√°cia de Teste: 40.00%\n",
      "√âpoca [9/40], Perda: 0.6927, Acur√°cia de Treino: 51.72%, Acur√°cia de Teste: 40.00%\n",
      "√âpoca [10/40], Perda: 0.6927, Acur√°cia de Treino: 51.72%, Acur√°cia de Teste: 40.00%\n",
      "√âpoca [11/40], Perda: 0.6928, Acur√°cia de Treino: 51.72%, Acur√°cia de Teste: 40.00%\n",
      "√âpoca [12/40], Perda: 0.6930, Acur√°cia de Treino: 51.72%, Acur√°cia de Teste: 40.00%\n",
      "√âpoca [13/40], Perda: 0.6929, Acur√°cia de Treino: 51.72%, Acur√°cia de Teste: 40.00%\n",
      "√âpoca [14/40], Perda: 0.6929, Acur√°cia de Treino: 51.72%, Acur√°cia de Teste: 40.00%\n",
      "√âpoca [15/40], Perda: 0.6924, Acur√°cia de Treino: 51.72%, Acur√°cia de Teste: 40.00%\n",
      "√âpoca [16/40], Perda: 0.6932, Acur√°cia de Treino: 51.72%, Acur√°cia de Teste: 40.00%\n",
      "√âpoca [17/40], Perda: 0.6936, Acur√°cia de Treino: 50.43%, Acur√°cia de Teste: 56.67%\n",
      "  --> Modelo salvo com a melhor acur√°cia de teste: 56.67%\n",
      "√âpoca [18/40], Perda: 0.6937, Acur√°cia de Treino: 51.82%, Acur√°cia de Teste: 40.00%\n",
      "√âpoca [19/40], Perda: 0.6926, Acur√°cia de Treino: 51.72%, Acur√°cia de Teste: 40.00%\n",
      "√âpoca [20/40], Perda: 0.6927, Acur√°cia de Treino: 53.60%, Acur√°cia de Teste: 36.67%\n",
      "√âpoca [21/40], Perda: 0.6922, Acur√°cia de Treino: 52.09%, Acur√°cia de Teste: 40.00%\n",
      "√âpoca [22/40], Perda: 0.6926, Acur√°cia de Treino: 52.71%, Acur√°cia de Teste: 43.33%\n",
      "√âpoca [23/40], Perda: 0.6920, Acur√°cia de Treino: 53.50%, Acur√°cia de Teste: 50.00%\n",
      "√âpoca [24/40], Perda: 0.6915, Acur√°cia de Treino: 54.85%, Acur√°cia de Teste: 43.33%\n",
      "√âpoca [25/40], Perda: 0.6910, Acur√°cia de Treino: 54.27%, Acur√°cia de Teste: 46.67%\n",
      "√âpoca [26/40], Perda: 0.6893, Acur√°cia de Treino: 52.11%, Acur√°cia de Teste: 40.00%\n",
      "√âpoca [27/40], Perda: 0.6881, Acur√°cia de Treino: 58.33%, Acur√°cia de Teste: 46.67%\n",
      "√âpoca [28/40], Perda: 0.6817, Acur√°cia de Treino: 58.95%, Acur√°cia de Teste: 56.67%\n",
      "√âpoca [29/40], Perda: 0.6780, Acur√°cia de Treino: 58.37%, Acur√°cia de Teste: 50.00%\n",
      "√âpoca [30/40], Perda: 0.6706, Acur√°cia de Treino: 59.88%, Acur√°cia de Teste: 63.33%\n",
      "  --> Modelo salvo com a melhor acur√°cia de teste: 63.33%\n",
      "√âpoca [31/40], Perda: 0.6602, Acur√°cia de Treino: 63.09%, Acur√°cia de Teste: 63.33%\n",
      "√âpoca [32/40], Perda: 0.6385, Acur√°cia de Treino: 64.62%, Acur√°cia de Teste: 66.67%\n",
      "  --> Modelo salvo com a melhor acur√°cia de teste: 66.67%\n",
      "√âpoca [33/40], Perda: 0.6326, Acur√°cia de Treino: 67.38%, Acur√°cia de Teste: 70.00%\n",
      "  --> Modelo salvo com a melhor acur√°cia de teste: 70.00%\n",
      "√âpoca [34/40], Perda: 0.6090, Acur√°cia de Treino: 68.74%, Acur√°cia de Teste: 63.33%\n",
      "√âpoca [35/40], Perda: 0.5903, Acur√°cia de Treino: 70.24%, Acur√°cia de Teste: 76.67%\n",
      "  --> Modelo salvo com a melhor acur√°cia de teste: 76.67%\n",
      "√âpoca [36/40], Perda: 0.5703, Acur√°cia de Treino: 72.14%, Acur√°cia de Teste: 70.00%\n",
      "√âpoca [37/40], Perda: 0.5503, Acur√°cia de Treino: 74.23%, Acur√°cia de Teste: 53.33%\n",
      "√âpoca [38/40], Perda: 0.5133, Acur√°cia de Treino: 75.39%, Acur√°cia de Teste: 46.67%\n",
      "√âpoca [39/40], Perda: 0.4967, Acur√°cia de Treino: 79.08%, Acur√°cia de Teste: 73.33%\n",
      "√âpoca [40/40], Perda: 0.4608, Acur√°cia de Treino: 82.06%, Acur√°cia de Teste: 76.67%\n",
      "\n",
      "‚úÖ Treinamento conclu√≠do!\n",
      "A melhor acur√°cia de teste alcan√ßada foi: 76.67%\n"
     ]
    }
   ],
   "source": [
    "# Modelo de Rede Neural para prever a tend√™ncia do IBOVESPA\n",
    "# Definindo o modelo de rede neural\n",
    "# Usaremos uma LSTM (Long Short-Term Memory) para capturar as depend√™ncias temporais dos dados de s√©ries temporais\n",
    "# A LSTM √© uma arquitetura de rede neural recorrente (RNN) que √© eficaz para sequ√™ncias de dados, como s√©ries temporais.\n",
    "\n",
    "print(\"\\nüìã Definindo o modelo de rede neural...\")\n",
    "class ModeloTendenciaIBOV(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(ModeloTendenciaIBOV, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "# Avalia√ß√£o do modelo\n",
    "# A fun√ß√£o avaliar_modelo recebe o modelo, o DataLoader e o dispositivo (CPU ou GPU)\n",
    "# Ela calcula a acur√°cia do modelo no conjunto de dados fornecido\n",
    "def avaliar_modelo(modelo, dataloader, device):\n",
    "    modelo.eval()\n",
    "    with torch.no_grad():\n",
    "        corretas = 0\n",
    "        total = 0\n",
    "        for lote_features, lote_targets in dataloader:\n",
    "            lote_features = lote_features.to(device)\n",
    "            lote_targets = lote_targets.to(device)\n",
    "            saidas = modelo(lote_features)\n",
    "            _, predicoes = torch.max(saidas.data, 1)\n",
    "            total += lote_targets.size(0)\n",
    "            corretas += (predicoes == lote_targets).sum().item()\n",
    "    acuracia = 100 * corretas / total\n",
    "    return acuracia\n",
    "\n",
    "\n",
    "\n",
    "#Loop de treinamento do modelo\n",
    "# Par√¢metros e setup do modelo\n",
    "print(\"\\nüìã Configurando os par√¢metros do modelo...\")\n",
    "SEMENTE_GLOBAL = 42\n",
    "definir_semente_reprodutibilidade_aprimorada(SEMENTE_GLOBAL)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "num_epocas = 40\n",
    "taxa_aprendizagem = 0.007\n",
    "num_features = X.shape[2]\n",
    "hidden_size = 64\n",
    "num_layers = 3\n",
    "output_size = 2\n",
    "modelo = ModeloTendenciaIBOV(num_features, hidden_size, num_layers, output_size).to(device)\n",
    "funcao_perda = nn.CrossEntropyLoss()\n",
    "otimizador = optim.Adam(modelo.parameters(), lr=taxa_aprendizagem)\n",
    "\n",
    "# Vari√°veis para salvar o melhor modelo\n",
    "melhor_acuracia_teste = 0.0\n",
    "caminho_melhor_modelo = 'melhor_modelo.pth'\n",
    "\n",
    "print(\"\\n‚úÖ Par√¢metros do modelo configurados com sucesso!\")\n",
    "print(f\"Dispositivo usado: {device}\")\n",
    "print(f\"N√∫mero de √©pocas: {num_epocas}\")\n",
    "print(f\"Tamanho do lote (batch size): {tamanho_lote}\")\n",
    "print(f\"N√∫mero de features: {num_features}\")\n",
    "print(f\"Tamanho do hidden layer: {hidden_size}\")\n",
    "print(f\"N√∫mero de camadas LSTM: {num_layers}\")\n",
    "print(f\"Tamanho da sa√≠da (output size): {output_size}\")\n",
    "\n",
    "print(\"\\nüìã Iniciando o treinamento com salvamento de checkpoint...\")\n",
    "\n",
    "for epoca in range(num_epocas):\n",
    "    modelo.train()\n",
    "    perda_total_epoca = 0\n",
    "    \n",
    "    for lote_features, lote_targets in dataloader_treino:\n",
    "        lote_features, lote_targets = lote_features.to(device), lote_targets.to(device)\n",
    "        saidas = modelo(lote_features)\n",
    "        perda = funcao_perda(saidas, lote_targets)\n",
    "        otimizador.zero_grad()\n",
    "        perda.backward()\n",
    "        otimizador.step()\n",
    "        perda_total_epoca += perda.item()\n",
    "\n",
    "    # Avalia√ß√£o ao final de cada √©poca\n",
    "    acuracia_treino = avaliar_modelo(modelo, dataloader_treino, device)\n",
    "    acuracia_teste = avaliar_modelo(modelo, dataloader_teste, device)\n",
    "    perda_media_epoca = perda_total_epoca / len(dataloader_treino)\n",
    "    \n",
    "    print(f'√âpoca [{epoca+1}/{num_epocas}], Perda: {perda_media_epoca:.4f}, Acur√°cia de Treino: {acuracia_treino:.2f}%, Acur√°cia de Teste: {acuracia_teste:.2f}%')\n",
    "\n",
    "    # Salvar o modelo se a acur√°cia de teste for a melhor at√© agora\n",
    "    if acuracia_teste > melhor_acuracia_teste:\n",
    "        melhor_acuracia_teste = acuracia_teste\n",
    "        # Salvamos um dicion√°rio contendo o estado do modelo e a acur√°cia\n",
    "        torch.save(modelo.state_dict(), caminho_melhor_modelo)\n",
    "        print(f\"  --> Modelo salvo com a melhor acur√°cia de teste: {melhor_acuracia_teste:.2f}%\")\n",
    "\n",
    "print(\"\\n‚úÖ Treinamento conclu√≠do!\")\n",
    "print(f\"A melhor acur√°cia de teste alcan√ßada foi: {melhor_acuracia_teste:.2f}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2bffd7",
   "metadata": {},
   "source": [
    "#### Avalia√ß√£o do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "5a91e952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Carregando o melhor modelo salvo de 'melhor_modelo.pth'...\n",
      "\n",
      "Matriz de Confus√£o:\n",
      "\n",
      "Verdadeiros positivos (TP): 11\n",
      "Falsos positivos (FP): 6\n",
      "Verdadeiros negativos (TN): 12\n",
      "Falsos negativos (FN): 1\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acur√°cia do teste calculada com sklearn: 76.67%\n"
     ]
    }
   ],
   "source": [
    "# Avalia√ß√£o final do melhor modelo\n",
    "# ##########################################################################\n",
    "# CARREGAR O MELHOR MODELO SALVO\n",
    "# ##########################################################################\n",
    "\n",
    "print(f\"\\n‚úÖ Carregando o melhor modelo salvo de '{caminho_melhor_modelo}'...\")\n",
    "melhor_modelo = ModeloTendenciaIBOV(num_features, hidden_size, num_layers, output_size).to(device)\n",
    "melhor_modelo.load_state_dict(torch.load(caminho_melhor_modelo))\n",
    "\n",
    "\n",
    "# Gerando as previs√µes para o conjunto de teste\n",
    "y_pred = []\n",
    "melhor_modelo.eval()\n",
    "for lote_features, _ in dataloader_teste:\n",
    "    lote_features = lote_features.to(device)\n",
    "    with torch.no_grad():\n",
    "        saidas = melhor_modelo(lote_features)\n",
    "    _, predicoes = torch.max(saidas.data, 1)\n",
    "    y_pred.extend(predicoes.cpu().numpy())\n",
    "\n",
    "# Gerando a matriz de confus√£o\n",
    "cm = confusion_matrix(y_teste_final, y_pred)\n",
    "print(\"\\nMatriz de Confus√£o:\")\n",
    "print(\"\\nVerdadeiros positivos (TP):\", cm[1, 1])\n",
    "print(\"Falsos positivos (FP):\", cm[0, 1])\n",
    "print(\"Verdadeiros negativos (TN):\", cm[0, 0])\n",
    "print(\"Falsos negativos (FN):\", cm[1, 0])\n",
    "# Plotando a matriz de confus√£o\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Baixa', 'Alta'])\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title('Matriz de Confus√£o - Melhor Modelo')\n",
    "plt.show()\n",
    "\n",
    "# Avalia√ß√£o final com sklearn\n",
    "test_accuracy = accuracy_score(y_teste_final, y_pred)\n",
    "print(f\"Acur√°cia do teste calculada com sklearn: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "5206da01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ META ATINGIDA! Acur√°cia >= 75%\n",
      "Acur√°cia final do melhor modelo (carregado) no conjunto de teste: 76.67%\n"
     ]
    }
   ],
   "source": [
    "# Verifica se atingiu a meta\n",
    "if test_accuracy >= 0.75:\n",
    "    print(\"üéØ META ATINGIDA! Acur√°cia >= 75%\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è  Meta n√£o atingida. Faltam {(0.75 - test_accuracy)*100:.2f}% para 75%\")\n",
    "\n",
    "# Avalia√ß√£o final do melhor modelo (carregado)\n",
    "acuracia_final_melhor_modelo = avaliar_modelo(melhor_modelo, dataloader_teste, device)\n",
    "print(f\"Acur√°cia final do melhor modelo (carregado) no conjunto de teste: {acuracia_final_melhor_modelo:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "desafio-01-v3 (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
